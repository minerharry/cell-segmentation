# Cell Segmentation and Training Library
A collection of functions to enable training of models on metamorph-collected image datasets and segmentation of those datasets. 

## Primary usage - Segmentation

The easiest way to use this library for segmentation is with the segment_experiment.py file. segement_experiment() is a function packed with presets for metamorph-collected datasets; when provided with an in_folder, an out_folder, and a cell_model name, nuc_model name, or both, it will segment the images from the in_folder to out_folder/cell and/or out_folder/nucleus as specified. It will look for the cell and nucleus models in the modelsfolder provided. The file can be run from the command line by providing paths to the input and output folders alternatingly: `python segment_experiment.py in_folder1 out_folder1 in_folder2 out_folder2` etc; make sure to surround any paths containing spaces with double quotes. Alterntaively, the segment_experiment function can be called from any python file; feel free to edit the `if __name__ == "__main__":` block at the end of the file. You can remove / comment out the argument parser stuff, or the for loop, and just set the paths to where you want them. If for whatever reason the segmentation fails, the code (see SourceProcessor's technical details) will be able to pick off from where it left off, so long as the *local_folder* provided to segment_experiment is the same. Currently there's a hack to create the folder name based off of the string representations of the input and output filenames (using `hash()`, which deterministically converts a given object to a number), but if you're doing it manually you might give the folders meaningfull names like the experiment date.

## Technical details

Core image processing code is in image_processing.py - holds the various functions for image I/O, splitting/stitching, stacking, etc. Also the SourceProcessor class, which manages 1) acquisition of images from remote storage (if applicable), 2) processing of those images using the mentioned preprocessing functions, 3) de-processing of segmented masks, 4) upload of images back to remote storage, and 5) acquisition/upload of models folders.
- The image processing functions are all meant to be used as functions-as-objects; that is, the sourceprocessor asks for an image processing function and deprocessing function, both of the type alias proc_type (defined in image_processing.py; takes in an image, returns one or more images). Those functions, passed as arguments, will be executed on each image in turn.
- Since there are several processing steps, multiple functions need to get "composed" into a single function which executes each step in sequence, which helpfully is what compose_proc_functions does
- Many image processing functions can't be used directly, but rather must be created and then used. For example, splitting an image requires parameters for the dimensions of the splitting sections, overlap, etc, so create_split_image_process_fn, when called with the appropriate parameters, returns a image splitting function which can then be passed to the sourceprocessor or composed with other image processing steps.
- The SourceProcessor class is meant to seamlessly manage processing of images, and will by default create a metadata file that records whether it has already done a particular processing step. **So long as the provided local folder is the same both times the code is run, the sourceprocessor will pick off from where it left off. Correspondingly, if the same local folder is used for multiple diferrent experiments without cleanup, then the SourceProcessor might incorrectly skip processing, resulting in segmenting the wrong images!** This can be disabled or overridden with keyword arguments. It can also be used as a context manager (e.g. used in a `with` statement), where (by default) it will, on exit, remove the folders/files it downloaded/managed to free up space. This can also be configured with arguments to its constructor.

The bulk of the code involved with actually performing segmentation and for interfacing with the models is divided between segmentation_and_training.py and models.py respectively. segmentation_and_training.py mostly interfaces with a SourceProcessor to handle the image/mask processing and download/upload and an abstract model class, defined in models.py, which actually performs segmentation. Models.py provides support for a handful of model libraries, but by far the most supported is keras models that use the pytorch backend.